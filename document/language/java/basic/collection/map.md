## HashMap

##### key hash值算法 ：
(key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);

问题：为什么这么计算？


问题：容量为什么是2的n次幂？
因为计算节点在table位置是是用 （k的哈希 & 容量-1），低位全是1，直接取原数值


数据结构：
1、整体是一个节点数组
2、每个节点，是一个链表，或者红黑树

链表转红黑树：
1、链表长度>=8 && 节点数 >= 64

红黑树：




如何扩容？




## ConcurrentHashMap

##### 无锁读操作：
在1.8中ConcurrentHashMap的get操作全程不需要加锁
get操作全程不需要加锁是因为Node的成员val是用volatile修饰的和数组用volatile修饰没有关系
数组用volatile修饰主要是保证在数组扩容的时候保证可见性


#### 如何在很短的时间内将大量数据插入到ConcurrentHashMap，换句话说，就是提高ConcurrentHashMap的插入效率

将大批量数据保存到map中有两个地方的消耗将会是比较大的：
第一个是扩容操作，第二个是锁资源的争夺。
第一个扩容的问题，主要还是要通过配置合理的容量大小和扩容因子，尽可能减少扩容事件的发生；
第二个锁资源的争夺，在put方法中会使用 synchronized 对头节点进行加锁，而锁本身也是分等级的，
因此我们的主要思路就是尽可能的避免锁等级。
所以，针对第二点，我们可以将数据通过通过ConcurrentHashMap的spread方法进行预处理，
这样我们可以将存在hash冲突的数据放在一个组里面，每个组都使用单线程进行put操作，
这样的话可以保证锁仅停留在偏向锁这个级别，不会升级，从而提升效率。

用线程池或者信号量来控制线程数量。
另外，可以将多组Hash冲突的数据集合到一个线程就OK，
只需要确保数据上只有一个线程持有锁，锁就不会升级了。

